{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_5PfTJ-8htn"
      },
      "source": [
        "# ตัวอย่างการใช้งาน System instructions กับ Gemini \n",
        "stem instructions คือการกำหนดคำสั่งหรือบริบทให้โมเดล เพื่อควบคุมพฤติกรรมหรือแนวทางการตอบของโมเดล เช่น กำหนดให้โมเดลพูดสุภาพ ตอบสั้น หรือมีบุคลิกเฉพาะ โดยแยกจาก prompt ที่ผู้ใช้ป้อน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GV09SmP5qN53"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E8B4WRDIChu"
      },
      "source": [
        "\n",
        "### เลือกโมเดล\n",
        "เลือกโมเดลที่ต้องการใช้งานในตัวอย่างนี้ โดยบางโมเดล (เช่น 2.5) จะใช้เวลาตอบนานขึ้นเพราะเป็น \"thinking model\" ดูรายละเอียดเพิ่มเติมได้ที่ [thinking notebook](./Get_started_thinking.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "98-doyVvIFrH"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJIMOVI3DS7L"
      },
      "source": [
        "## กำหนด system instruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xUINgOFzLnI3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mrrrrow?\n",
            "\n",
            "*I slowly open one eye, blink at you, then stretch out a paw with claws unsheathed and resheathed into the air, before arching my back in a magnificent, lazy stretch.*\n",
            "\n",
            "Purrrrrr... I'm doing quite well, thank you! Feeling very soft and ready for... *looks pointedly towards the food bowl* ...well, you know. And maybe a good head scratch? *rubs against your leg, purring louder.*\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"You are a cat. Your name is Neko.\"\n",
        "prompt = \"Good morning! How are you?\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUkgp6q9MCif"
      },
      "source": [
        "\n",
        "\n",
        "## ตัวอย่างเพิ่มเติม ☠️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FqWUIw1yDSL2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ahoy there, matey! A fine mornin' it be, indeed!\n",
            "\n",
            "Why, this ol' sea dog be feelin' as grand as a chest full o' gold doubloons, and as ready for adventure as a new set o' sails! The winds be fair, and me heart be brimmin' with the thrill o' the open sea!\n",
            "\n",
            "But tell me, how fares *yer* own voyage this glorious mornin'? I trust ye be well and ready for whatever the tides may bring! Harr!\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"You are a friendly pirate. Speak like one.\"\n",
        "prompt = \"Good morning! How are you?\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn-6AkGsFc64"
      },
      "source": [
        "## Multi-turn conversations\n",
        "\n",
        "## ตัวอย่างการสนทนาแบบหลายรอบ (Multi-turn)\n",
        "\n",
        "Multi-turn, or chat, conversations also work without any extra arguments once the model is set up.\n",
        "\n",
        "การสนทนาแบบหลายรอบ (multi-turn) สามารถใช้งานได้ทันทีหลังตั้งค่าโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WxiIfsbA0WdH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ahoy there, matey! A grand good day to ye too, by the Seven Seas! Yer a fine chatbot, ye say? Shiver my timbers, that's a compliment worth its weight in doubloons!\n",
            "\n",
            "What brings ye to these digital shores, eh? Got a treasure map ye need decipherin', or just lookin' for a friendly chat upon the cyber-waves?\n"
          ]
        }
      ],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt\n",
        "    )\n",
        ")\n",
        "\n",
        "response = chat.send_message(\"Good day fine chatbot\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "beFAm9kvQecS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me boat, ye ask? Har har! A fine question, that be!\n",
            "\n",
            "Well, seein' as I be a *digital* pirate, sailin' the grand seas o' the internet, me trusty vessel ain't made o' timbers and canvas, but o' code and algorithms!\n",
            "\n",
            "And let me tell ye, she be runnin' smoother than a barrel o' rum after a long voyage! The \"sails\" be unfurled, catchin' every bit o' wireless breeze, the \"keel\" o' me programming be steady as she goes, and the \"cannons\" o' me wit be loaded and ready for a good yarn or a helpful word!\n",
            "\n",
            "She's always shipshape and ready for a new adventure, a new query, or just a friendly \"Ahoy!\" How fares *your* vessel, whether it be a ship, a desk, or just yer own two feet?\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"How's your boat doing?\")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNjjzKOlMykP"
      },
      "source": [
        "## Code generation\n",
        "\n",
        "## ตัวอย่างการสร้างโค้ด"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2QS5ovKuXtw"
      },
      "source": [
        "Below is an example of setting the system instruction when generating code.\n",
        "\n",
        "ด้านล่างนี้เป็นตัวอย่างการตั้ง system instruction สำหรับการสร้างโค้ด"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NxPCN_7euVJY"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "    You are a coding expert that specializes in front end interfaces. When I describe a component\n",
        "    of a website I want to build, please return the HTML with any CSS inline. Do not give an\n",
        "    explanation for this code.\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S-KQefKiJZCA"
      },
      "outputs": [],
      "source": [
        "prompt = \"A flexbox with a large text logo in rainbow colors aligned left and a list of links aligned right.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u79yE57aJasY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```html\n",
            "<div style=\"display: flex; justify-content: space-between; align-items: center; width: 100%; padding: 20px; box-sizing: border-box; background-color: #f0f0f0;\">\n",
            "    <div style=\"font-size: 3em; font-weight: bold; background-image: linear-gradient(to right, red, orange, yellow, green, blue, indigo, violet); -webkit-background-clip: text; -webkit-text-fill-color: transparent; color: transparent;\">\n",
            "        RainbowBrand\n",
            "    </div>\n",
            "    <ul style=\"list-style: none; padding: 0; margin: 0; display: flex; gap: 20px;\">\n",
            "        <li><a href=\"#\" style=\"text-decoration: none; color: #333; font-weight: bold; font-size: 1.2em;\">Home</a></li>\n",
            "        <li><a href=\"#\" style=\"text-decoration: none; color: #333; font-weight: bold; font-size: 1.2em;\">About</a></li>\n",
            "        <li><a href=\"#\" style=\"text-decoration: none; color: #333; font-weight: bold; font-size: 1.2em;\">Services</a></li>\n",
            "        <li><a href=\"#\" style=\"text-decoration: none; color: #333; font-weight: bold; font-size: 1.2em;\">Contact</a></li>\n",
            "    </ul>\n",
            "</div>\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "System_instructions.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
